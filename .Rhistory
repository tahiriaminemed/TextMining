library(mallet)
library(rJava)
library(mallet)
library(rJava)
library(mallet)
setwd("~/Desktop/tm")
source('novel_characters1.R',print.eval=TRUE)
saga <- readLines("[Rois Maudits-1] Le Roi de fer - Druon,Maurice.txt", encoding="UTF-8")
lda.id <- 1:length(saga)
token.regexp <- "\\p{L}[\\p{L}\\p{P}]+\\p{L}"
stoplist <- "Stop-words-french.txt"
mallet.instances <- mallet.import(
as.character(lda.id), saga, stoplist, token.regexp = token.regexp)
topic.model <- MalletLDA(num.topics=140)
topic.model$loadDocuments(mallet.instances)
topic.model$train(3000)
topic.model$maximize(20)
characters <- characters_extraction(saga)
characters
characters <- sapply(characters, function(x) unlist(strsplit(tolower(x), "[^[:alpha:]]")))
characters
index.vocab <- match(characters,vocabulary)
rm(list = ls())
library(rJava)
library(mallet)
source('novel_characters1.R',print.eval=TRUE)
saga <- readLines("[Rois Maudits-1] Le Roi de fer - Druon,Maurice.txt", encoding="UTF-8")
lda.id <- 1:length(saga)
token.regexp <- "\\p{L}[\\p{L}\\p{P}]+\\p{L}"
stoplist <- "Stop-words-french.txt"
mallet.instances <- mallet.import(
as.character(lda.id), saga, stoplist, token.regexp = token.regexp)
topic.model <- MalletLDA(num.topics=140)
topic.model$loadDocuments(mallet.instances)
vocabulary <- topic.model$getVocabulary()
topic.model$train(3000)
topic.model$maximize(20)
characters <- characters_extraction(saga)
characters <- sapply(characters, function(x) unlist(strsplit(tolower(x), "[^[:alpha:]]")))
index.vocab <- match(characters,vocabulary)
doc.topics <- mallet.doc.topics(topic.model, smoothed=T, normalized=T)
topic.words <- mallet.topic.words(topic.model, smoothed=T, normalized=T)
num.topics <- 1:140
mat.w_z <- do.call(cbind,
sapply(num.topics,
function(x) format(mallet.top.words(topic.model, topic.words[x,]))))
colnames(mat.w_z) <- sapply(num.topics, function(x) c(paste("z",x), "p(w/z)"))
char.pos <-  Reduce(rbind, sapply(list,  function(m) which( mat.w_z == m, arr.ind = TRUE)))
char.pos
mat.w_z
View(mat.w_z)
char.pos
char.dist <- matrix(nrow = length(characters), ncol = 3)
{
char.dist[i,1] <- mat.w_z[char.pos[i,1], char.pos[i,2] ] #the charcater name
char.dist[i,2] <- char.pos[i,2] #the topic containing the character
char.dist[i,3] <- mat.w_z[char.pos[i,1], char.pos[i,2]+1]  #probability for a character to belong to the topic
}
colnames(mat.w_z)
colnames(mat.w_z) <- sapply(num.topics, function(x) c(paste("z",x), "p(w/z)"))
colnames(mat.w_z)
char.pos <-  Reduce(rbind, sapply(list,  function(m) which( mat.w_z == m, arr.ind = TRUE)))
char.pos
rm(list=ls())
library(tm)
library(rJava)
library(coreNLP)
install.packages("coreNLP")
library(tm)
library(NLP)
library(coreNLP)
install.packages("coreNLP")
install.packages("XML")
library(XML)
install.packages("coreNLP")
library(coreNLP)
library(rJava)
initCoreNLP(parameterFile = NULL, mem = "4g")
downloadCoreNLP()
initCoreNLP()
library(rJava)
initCoreNLP()
version
.jinit()
.jcall("java/lang/System","S","getProperty","java.version")
initCoreNLP()
library(rJava)
downloadCoreNLP()
initCoreNLP()
rm(list = ls())
library(tm)
library(NLP)
library(XML)
library(coreNLP)
library(rJava)
downloadCoreNLP()
initCoreNLP()
